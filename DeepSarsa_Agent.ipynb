{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff5db117",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:   0 | score:   1 | epsilon: 0.999\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 0.13989052 -0.6147008  -0.3598695   0.02612967 -0.25860947]], shape=(1, 5), dtype=float32)\n"
     ]
    },
    {
     "ename": "TclError",
     "evalue": "invalid command name \".!canvas\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 99\u001b[0m\n\u001b[0;32m     96\u001b[0m action \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mget_action(state)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# 선택한 행동으로 환경에서 한 타임스텝 진행 후 샘플 수집\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m next_state, reward, done \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m next_state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(next_state, [\u001b[38;5;241m1\u001b[39m, state_size])\n\u001b[0;32m    101\u001b[0m next_action \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mget_action(next_state)\n",
      "File \u001b[1;32m~\\minigame\\reinforcement-learning-kr-v2-master\\1-grid-world\\5-deep-sarsa\\environment.py:141\u001b[0m, in \u001b[0;36mEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounter \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmove_rewards()\n\u001b[1;32m--> 141\u001b[0m next_coords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrectangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m check \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_if_reward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoords_to_state(next_coords))\n\u001b[0;32m    143\u001b[0m done \u001b[38;5;241m=\u001b[39m check[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mif_goal\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\minigame\\reinforcement-learning-kr-v2-master\\1-grid-world\\5-deep-sarsa\\environment.py:210\u001b[0m, in \u001b[0;36mEnv.move\u001b[1;34m(self, target, action)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmove\u001b[39m(\u001b[38;5;28mself\u001b[39m, target, action):\n\u001b[1;32m--> 210\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m     base_action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# 상\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\minigame\\lib\\tkinter\\__init__.py:2766\u001b[0m, in \u001b[0;36mCanvas.coords\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   2762\u001b[0m \u001b[38;5;124;03m\"\"\"Return a list of coordinates for the item given in ARGS.\"\"\"\u001b[39;00m\n\u001b[0;32m   2763\u001b[0m \u001b[38;5;66;03m# XXX Should use _flatten on args\u001b[39;00m\n\u001b[0;32m   2764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtk\u001b[38;5;241m.\u001b[39mgetdouble(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m\n\u001b[0;32m   2765\u001b[0m                    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtk\u001b[38;5;241m.\u001b[39msplitlist(\n\u001b[1;32m-> 2766\u001b[0m            \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcoords\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)]\n",
      "\u001b[1;31mTclError\u001b[0m: invalid command name \".!canvas\""
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from environment_deepsarsa import Env\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# 딥살사 인공신경망\n",
    "class DeepSARSA(tf.keras.Model):\n",
    "    def __init__(self, action_size):  # action_size = 5\n",
    "        super(DeepSARSA, self).__init__()\n",
    "        self.fc1 = Dense(30, activation='relu')\n",
    "        self.fc2 = Dense(30, activation='relu')\n",
    "        self.fc_out = Dense(action_size)  # 출력층은 5개로\n",
    "\n",
    "    def call(self, x):  \n",
    "        x = self.fc1(x)  # x를 입력받아 x를 출력\n",
    "        x = self.fc2(x)\n",
    "        q = self.fc_out(x)\n",
    "        return q\n",
    "\n",
    "\n",
    "# 그리드월드 예제에서의 딥살사 에이전트\n",
    "class DeepSARSAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # 상태의 크기와 행동의 크기 정의\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        # 딥살사 하이퍼 파라메터\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "        self.epsilon = 1.  \n",
    "        self.epsilon_decay = 0.9999\n",
    "        self.epsilon_min = 0.01\n",
    "        self.model = DeepSARSA(self.action_size)  # 위에 모델\n",
    "        self.optimizer = Adam(learning_rate=self.learning_rate)  # Adam 이라는 수식에 learning_rate 의 걸음을 넣어줌\n",
    "\n",
    "    # 입실론 탐욕 정책으로 행동 선택\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:  # 입실론 값보다 작거나 같은 값이 뽑히면\n",
    "            return random.randrange(self.action_size)  # [0, 1, 2, 3, 4] 중에 임의로 이동\n",
    "        else:\n",
    "            q_values = self.model(state)  # 아니면 self.model()에 state(15개의 입력을 넣어준다)를 def_call에 x가 곧 state임\n",
    "            return np.argmax(q_values[0])  # [[[],[]]][0] = [[],[]]\n",
    "\n",
    "    # <s, a, r, s', a'>의 샘플로부터 모델 업데이트\n",
    "    def train_model(self, state, action, reward, next_state, next_action, done):\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay  # 현재 입실론이 0.01보다 크면 0.9999를 곱해준다 \n",
    "\n",
    "        # 학습 파라메터\n",
    "        model_params = self.model.trainable_variables  # trainable_variables에 의해 임의이 값이 w가중치로 들어가서 계산이 시작된다. // 15개가 30개로 들어가고 30개가 30개로 중간중간 b가 더해지는\n",
    "        with tf.GradientTape() as tape:  # 잘모르겠음\n",
    "            tape.watch(model_params)  # 잘모르겠음\n",
    "            predict = self.model(state)[0]  # 다섯개의 소수점이 2차원 리스트로 나오므로 1차원으로 뽑기위해 0\n",
    "            one_hot_action = tf.one_hot([action], self.action_size)  # 액션은 1,2,3,4,5중에서 하나를 뽑고 [1,2,3,4,5]에서 나온값을 제외하고 0으로 바꿔준다 나온건 1\n",
    "            predict = tf.reduce_sum(one_hot_action * predict, axis=1)  # 다시 소수점으로 바꿔주고 1이었던 남은 소수점하나만 살리기위해 더해줌\n",
    "\n",
    "            # done = True 일 경우 에피소드가 끝나서 다음 상태가 없음\n",
    "            next_q = self.model(next_state)[0][next_action]  # 2차원리스트에서 1차원으로 바꿔준 다섯개의 상태에서 다음 행동 하나를 선택해서 밑으로 보내주고\n",
    "            target = reward + (1 - done) * self.discount_factor * next_q\n",
    "\n",
    "            # MSE 오류 함수 계산\n",
    "            loss = tf.reduce_mean(tf.square(target - predict))  # reduce_mean 1차원리스트를 빼준다.\n",
    "        \n",
    "        # 오류함수를 줄이는 방향으로 모델 업데이트\n",
    "        grads = tape.gradient(loss, model_params)  # model_params의 6가지 가중치에 오류함수와 gradient를 통해서 가중치에 대한 비율를 구해주고 \n",
    "        self.optimizer.apply_gradients(zip(grads, model_params))  # grads 에 저장된 각각의 비중과 가중치를 apply_gradients를 이용해서 업데이트해준다.\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 환경과 에이전트 생성\n",
    "    env = Env(render_speed=0.01)\n",
    "    state_size = 15\n",
    "    action_space = [0, 1, 2, 3, 4]\n",
    "    action_size = len(action_space)\n",
    "    agent = DeepSARSAgent(state_size, action_size)\n",
    "    \n",
    "    scores, episodes = [], []\n",
    "\n",
    "    EPISODES = 5\n",
    "    for e in range(EPISODES):\n",
    "        done = False\n",
    "        score = 0\n",
    "        # env 초기화\n",
    "        state = env.reset()ㄴ\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "\n",
    "        while not done:\n",
    "            # 현재 상태에 대한 행동 선택\n",
    "            action = agent.get_action(state)\n",
    "            # 선택한 행동으로 환경에서 한 타임스텝 진행 후 샘플 수집\n",
    "            next_state, reward, done = env.step(action)\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "            next_action = agent.get_action(next_state)\n",
    "\n",
    "            # 샘플로 모델 학습\n",
    "            agent.train_model(state, action, reward, next_state, \n",
    "                                next_action, done)\n",
    "            score += reward\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                # 에피소드마다 학습 결과 출력\n",
    "                print(\"episode: {:3d} | score: {:3d} | epsilon: {:.3f}\".format(\n",
    "                      e, score, agent.epsilon))\n",
    "\n",
    "                scores.append(score)\n",
    "                episodes.append(e)\n",
    "                pylab.plot(episodes, scores, 'b')\n",
    "                pylab.xlabel(\"episode\")\n",
    "                pylab.ylabel(\"score\")\n",
    "                pylab.savefig(\"./save_graph/graph.png\")\n",
    "                pylab.show()\n",
    "\n",
    "\n",
    "\n",
    "        # 100 에피소드마다 모델 저장\n",
    "        if e % 100 == 0:\n",
    "            agent.model.save_weights('save_model/model', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb2fadf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax([[-0.55592585], [-0.7712781],   [0.9211373] , [-0.8641545] , [-0.3696173 ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b463481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
